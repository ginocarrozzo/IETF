<?xml version="1.0" encoding="US-ASCII"?>
<!DOCTYPE rfc SYSTEM "rfc2629.dtd" [
<!ENTITY RFC2119 SYSTEM "http://xml.resource.org/public/rfc/bibxml/reference.RFC.2119.xml">
]>
<?xml-stylesheet type="text/xsl" href="rfc2629.xslt" ?>
<!-- used by XSLT processors -->
<!-- OPTIONS, known as processing instructions (PIs) go here. -->
<!-- For a complete list and description of PIs,
please see http://xml.resource.org/authoring/README.html. -->
<!-- Below are generally applicable PIs that most I-Ds might want to use. -->
<?rfc strict="yes" ?>
<!-- give errors regarding ID-nits and DTD validation -->
<!-- control the table of contents (ToC): -->
<?rfc toc="yes"?>
<!-- generate a ToC -->
<?rfc tocdepth="2"?>
<!-- the number of levels of subsections in ToC. default: 3 -->
<!-- control references: -->
<?rfc symrefs="yes"?>
<!-- use symbolic references tags, i.e, [RFC2119] instead of [1] -->
<?rfc sortrefs="yes" ?>
<!-- sort the reference entries alphabetically -->
<!-- control vertical white space: 
(using these PIs as follows is recommended by the RFC Editor) -->
<?rfc compact="yes" ?>
<!-- do not start each main section on a new page -->
<?rfc subcompact="no" ?>
<!-- keep one blank line between list items -->
<!-- end of popular PIs -->
<rfc category="info" docName="draft-felix-nfvrg-recursive-orchestration-00" ipr="trust200902">
	<front>
		<title abbrev="Recursive orchestration">Recursive orchestration of federated virtual network functions</title>
		<author fullname="Gino Carrozzo (Ed.)" initials="G.Carrozzo" surname="Carrozzo" role="editor">
			<organization>Nextworks</organization>
			<address>
				<postal>
					<street>via Livornese 1027</street>
					<city>Pisa</city>
					<!-- <region/> -->
					<code>56122</code>
					<country>Italy</country>
				</postal>
				<!--  <phone/> -->
				<!-- <facsimile/> -->
				<email>g.carrozzo@nextworks.it</email>
				<!-- <uri/> -->
			</address>
		</author>
		<author fullname="Kostas Pentikousis (Ed.)" initials="K. Pentikousis" surname="Pentikousis" role="editor">
			<organization>EICT</organization>
			<address>
				<postal>
					<street>Torgauer Strasse 12-15</street>
					<city>Berlin</city>
					<!-- <region/> -->
					<code>10829</code>
					<country>Germany</country>
				</postal>
				<!--  <phone/> -->
				<!-- <facsimile/> -->
				<email>k.pentikousis@eict.de</email>
				<!-- <uri/> -->
			</address>
		</author>
		<!-- 		<author fullname="" initials="" surname="">
			<organization></organization>
			<address>
			<postal>
			<street></street>
			<city></city>
			<region/>
			<code></code>
			<country></country>
			</postal>
			<phone/>
			<facsimile/>
			<email></email>
			<uri/>
			</address>
		</author> -->
		<date month="July" year="2015"/>
		<!-- <area/> -->
		<workgroup>Internet Research Task Force NFVRG </workgroup>
		<keyword>Resource orchestration</keyword>
		<keyword>Resource federation</keyword>
		<keyword>Recursive orchestration</keyword>
		<!-- <keyword/> -->
		<abstract>
			<t>
				This document introduces a policy-based resource management 
				and orchestration framework which aims at contributing 
				towards the current namesake NFVRG near-term work items. 
			</t>
			<t>
				It describes key points of the recursive resource 
				orchestration framework developed within the wider research 
				area of federated	virtual network function orchestration. 
				The document also relates this effort with respect to 
				other orchestration frameworks, thus addressing both the 
				NFV research and practitioner communities.
			</t>
		</abstract>
	</front>
	<middle>
		<section title="Introduction">
			<t>
				Today&apos;s Internet is a concatenation of IP networks 
				interconnected by many distributed functions integrated 
				into a plethora of highly specialized middleboxes. These 
				elements implement complex network functions like firewalls, 
				NATs, DPI, traffic scrubbing, etc. 
				The product is a quite complex and rigid internetworking 
				system in which network administrators and users cannot 
				easily determine what is happening to traffic flows as 
				they go toward destinations.
				In the last decade networks, servers, storage technologies, 
				and applications have all undergone significant changes 
				with the introduction of virtualization, network overlays,
				and orchestration. Such technologies have allowed network 
				operators and service providers to easily introduce a 
				variety of (proprietary) hardware-based appliances in order
				to improve their network manageability as well as rapidly 
				launch new services, keeping up with the pace of their 
				users demand. 
				Therefore, the current Internet  looks like a concatenation 
				of networks with many distributed functions, implemented 
				via a plethora of highly specialized middleboxes which 
				implement firewalls, DPI, NAT, traffic scrubbing, etc. 
				<xref target="middlebox"/>.
			</t>
			<t>	
				Software Define Networking and programmable virtualized 
				network functions for flow processing are rapidly changing 
				the current scenario, extending the support of network functions
				by virtualized and chained appliances beyond the  virtual 
				L2 switching over IP networks (e.g. VXLAN, GRENV, STT) and 
				the basic LAN based flow pinpointing.
			</t>
			<t>	
				Virtual Functions of this kind, for network and non network (e.g. 
				computing) tasks, are generally available in heterogeneous pools 
				under different	administrative domains, being them related to the hosting 
				infrastructures in which they originate. 
				It is emerging a need to interconnect, federate and implement policy 
				control on these pools of virtual resources, in order to abstract different 
				infrastructures, resources and functions, as well as procedures by 
				physical operators and infrastructure owners. This can allow 
				defining larger virtual overlays where different resources and functions 
				are deployed, combined and handled in the form of virtual instances 
				irrespective of the administrative domain and specific technology 
				from which they originate. 

				Examples of application contexts in which this federation of virtual 
				function pools may occur are:
			</t>
			<t>
				<list style="symbols">
					<t> 
						large scale experimentation over programmable networks, which 
						allows to reserve slices of network and non-network resources
						from different federated providers to run experiments on network 
						control, protocols and algorithms at large scale (e.g. <xref target="FELIX"/>);
					</t>
					<t> 
						virtual infrastructure operators, who intend to implement their 
						network service offer over a completely virtual infrastructure 
						in the form of virtual network nodes and functions, 
						virtual servers and storage, etc., all procured as a service 
						from physical providers.
					</t>
				</list> 
			</t>
			<t>
				This document discusses key points of the recursive resource 
				orchestration framework developed within the wider research 
				area of federated virtual network function orchestration. 
				The proposed architecture allows federation and integration 
				of different network and computing resources residing in a 
				multi-domain heterogeneous environment across different providers. 
				To achieve this, the architecture uses a combination of recursive 
				and hierarchical configurations for orchestration, request delegation 
				and inter-domain dependency management, with resource orchestrating 
				entities (Resource Orchestrators, RO) responsible for 
				synchronization of resources available in particular
				administrative domains.
			</t>
			<t>
				This document is being discussed on the nfvrg@irtf.org mailing list.
			</t>
		</section>

		<!-- 		<section title="Conventions used in this document">
			<t>
				The key words "MUST", "MUST NOT", "REQUIRED", "SHALL", "SHALL NOT", 
				"SHOULD", "SHOULD NOT", "RECOMMENDED", "MAY", and "OPTIONAL" in this
				document are to be interpreted as described in <xref target="RFC2119"/>.
			</t>
		</section>
 -->		
		<section title="Terminology">
			<t>
				The following terminology is used in this document.
			</t>
			<t>
				<list style="hanging">
					<t hangText="Virtual Network Function(VNF).">
						One or more virtual machines running different 
						software and processes, on top of industry standard 
						high volume servers, switches and storage, or even 
						cloud computing infrastructure, and capable of 
						implementing network functions traditionally 
						implemented via custom hardware appliances and 
						middleboxes (e.g. router, NAT, Firewall, 
						load-balancer, etc.)
					</t>
					<t hangText="VNF Island.">
						A set of virtualized network functions and related 
						network and IT resources under the same administrative 
						ownership/control. A VNF island could consist of 
						multiple zones, each characterized by a specific 
						set of control tools &amp; interfaces.
					</t>
					<t hangText="VNF Zone.">
						A set of virtual network functions grouped for 
						homogeneity of technologies and/or control tools 
						and/or interfaces (e.g. L2 switching zone, optical 
						switching zone, OF protocol controlled zone, other 
						transit domain zone with a control interface). 
						The major goal of defining SDN zones is to implement 
						appropriate policies for increasing availability, 
						scalability and control of the different resources 
						of the island. Examples of zone definitions are 
						available in popular Cloud Management Systems 
						(CMS) like Cloudstack (e.g. refer to the Cloudstack 
						Infrastructure partitioning into regions, zones, 
						pods, etc., <xref target="cloudstack"/>) and OpenStack
						(e.g. refer to the infrastructure partitioning in 
						availability zones and host aggregates <xref target="openstack"/>).
					</t>
					<t hangText="Transit network domains.">
						The network domains use a Bandwidth on Demand Interface 
						to expose automatically and on-demand control of 
						connectivity services and, optionally, inter-domain 
						topology exchange. In order to federate resources 
						belonging to distant facilities (i.e. islands/zones) it 
						must be ensured that interconnectivity is provided 
						on-demand and with a specific granularity. 
					</t>
					<t hangText="Slice.">
						A user-defined subset of virtual networking and 
						IT resources, created from the physical resources 
						available in federated VNF Zones and VNF Islands. 
						A VNF Slice has the basic property of being isolated 
						from other slices defined over the same physical resources, 
						and being dynamically extensible across multiple 
						VNF Islands. Each VNF Slice instantiates the specific 
						set of control tools of the specific zones it traverses.
					</t>
					<t hangText="Resource Orchestrator (RO)."> 
						Entity responsible for orchestrating end-to-end 
						network service and resources reservation in terms 
						of compute, storage	and network functions over the 
						infrastructure, as well as delegating end-to-end 
						resource and service provisioning in a 
						technology-agnostic way.
					</t>
					<t hangText="Resource Managers (RMs)."> 
						Entity responsible for controlling and managing 
						different types of resources and/or network 
						functions.
					</t>
				</list>
			</t>
		</section>

		<section title="Recursive orchestration in federated virtual environments">
			<section title="Problem Statement">
				<t>	
					The coordinates creation of a virtual environment with pools of
					virtual network and non-network functions from heterogeneous, 
					multi-domain and geographically distributed facilities 
					requires appropriate tools for resource and virtual function 
					management and control capable of orchestration and 
					policy control across VNF islands, zones and domains 
					defined above.
				</t>
				<t>	
					Elements that belong to this control and orchestration 
					layer operate in a hierarchical way (parent-child) for 
					efficient multi-domain information management and sharing. 
					This is generally referred as Inter-island Orchestration 
					Space <xref target="FELIX-D2.1"/>  <xref target="FELIX-D2.2"/>.
				</t>
				<t>
					Once the set of virtual network and non-network functions 
					is determined, reserved and deployed across the different
					islands, the resulting  virtual network environment is 
					ready for being used as a User Space by any tool or application
					the user wants to deploy in it.
				</t>
				<t>
					In the Inter-island Orchestration Space (see 
					<xref target="fig-mro"/>), Resource Orchestrators (RO) 
					are responsible for orchestrating end-to-end network services
					and resources reservations in the whole infrastructure. 
					Moreover, ROs should be able to delegate end-to-end 
					resource and service provisioning in technology-agnostic way. 
				</t>
				<t>
					ROs are connected to different types of Resource Managers (RMs),
					which are in turn used to control and manage different 
					kinds of technological resources. For example, the 
					VNF RM WAN side provides connectivity between L1/L2 
					network domains at the two ends. 
					This management can be achieved using frame, packet or 
					circuit switching technologies and should support 
					different protocols.
				</t>
				<t>
					On the other hand, the VNF RM (LAN side) manages the 
					network infrastructure composed of SDN-enabled devices, 
					e.g. OpenFlow switches or routers. In short, it can 
					control the user traffic environment by updating flow
					tables in physical devices. 
				</t>
				<t>
					In addition, the Virtual Function pool RM for computing resources
					is responsible for setting up and configuring computing 
					resources, i.e. creating new virtual machine instances,
					powering on/off instances, network interface card 
					configuration, etc.
				</t>
				<t>
					Authentication and Authorization Infrastructure (AAI) 
					for authenticating and authorizing users, is a cross 
					layer function in the Inter-island Orchestration Space, 
					because it serving as a &apos;trust anchor&apos; to facilitate
					authN/authZ procedures in federated facilities.
				</t>
				<t>
					Similarly, Monitoring allows to retrieve, correlate 
					and abstract statistics from the different components 
					of the physical and virtual resource pools and from 
					the user's slice. 
				</t>
				<t>	
					<xref target="fig-mro"/> shows a parent RO 
					coordinating orchestration actions at NFV island level 
					under the responsibility of two child ROs, each 
					orchestrating different types of RMs for the different
					kinds of virtual network and non-network function pools.
				</t>

				<figure title="Recursive Orchestration architecture model" align="center" anchor="fig-mro">
					<preamble/>
					<artwork>
						<![CDATA[ 				
+---+           +-------------------------------------------+    +---+
|   |           |          RESOURCE ORCHESTRATOR - RO       |    |   |
|   |-----------|                (parent)                   |----|   |
|   |           +-------------------------------------------+    |   |
|   |                     |                              |       |   |
|   |                     |                              |       |   |
|   |  +-------------------------------------+     +---------+   |   |
| M |  |                  RO                 |     |    RO   |   |   |
| O |--|               (child)               |     | (child) |---|   |
| N |  +-------------------------------------+     +---------+   | A |
| I |        |             |            |                |       | A |
| T |        |             |            |                |       | A |
| O |  +-----------+ +----------+ +----------+    +-----------+  |   |
| R |  |  VF POOL  | | VNF POOL | | VNF POOL |    |  Virtual  |  |   |
| I |--|  MANAGER  | | MANAGER  | | MANAGER  |    |    pool   |--|   |
| N |  |(computing)| |(LAN side)| |(WAN side)|    | manager(s)|  |   |
| G |  +-----------+ +----------+ +----------+    +-----------+  |   |
|   |        |             |             |              |        |   |
|   |  +----------+  +----------+ ----------+      +----------+  |   |
|   |--|    VF    |  |    VNF   | |    VNF   |     |    VNF   |--|   |
+---+  +----------+  +----------+ +----------+     +----------+  +---+
]]>
					</artwork>
					<postamble/>
				</figure>


			</section>

			<section title="Resource Orchestrator">
				<t>	
					RO is the entity that orchestrates the different resources
					in the Inter-island Orchestration Space.
				</t>
				<t>
					There are two different modes in which RO may operate: 
				</t>
				<t>
					<list style="symbols">
						<t> Parent </t>
						<t> Child </t>
					</list>
				</t>
				<t>
					For an inter-island federation, RO operates in parent 
					mode and attaches to child ROs, whilst in child mode ROs
					communicate with RMs.
				</t>
				<t>
					One of RO's main objectives is to forward requests within 
					the infrastructure, either by:
				</t>
				<t>
					<list style="symbols">
						<t> 
							Passing user requests to the appropriate 
							resource management systems (RMs) in the 
							layer below, as with any hierarchical mode.
						</t>
						<t> 
							Proxying requests between other ROs in a 
							recursive mode, depending on the federation 
							policy that is configured for the domain where 
							the RO is located. For this to work it is 
							necessary to ensure similar interfaces for 
							each orchestrator.
						</t>
					</list>
				</t>
				<t>
					Key functions of the RO can be summarized as follows. 
					RO manages the different VNF islands and users in terms 
					of their resource and data access policies. 
					It mediates between the user and the technology 
					specific to a Resource Manager (RM) by means 
					of delegation. It is expected that different RMs will 
					handle, for example, technology-dependent aspects in SDN domains
					(VNF RM LAN side) and transit network domains (VNF RM WAN side),
					as well non-network resource pools. 
					As part of this mediation, the RO will engage in the creation 
					(provisioning), maintenance, monitoring, and deletion 
					(release) of the used slices.
				</t>
				<t>
					RO also maintains a high-level cross-island topological view, 
					which summarizes the different resources pools available 
					along with their inter-connections. 
					This topology view is initialized and updated by the underlying 
					RMs, thus implementing a distributed hierarchical resource 
					discovery function. It determines which domains and which 
					inter-domain resources should be used to instantiate a 
					given end-to-end service for a particular experimenter&apos;s slice. 
				</t>
				<t>
					For example, based on a user request for a given type of 
					service to be instantiated in two remote islands, parent RO 
					determines which specific resource domains should be involved.
				</t>
				<t>
					Finally,  RO coordinates and ensures that the correct 
					sequence of actions takes place with respect to the 
					operation of the technology-specific RMs. 
					This includes the provisioning of the slice resources as 
					per user&apos;s requirements. 
				</t>
				<t>
					RO also collects and correlates status alarms and warnings
					on resources, either generated by the resources themselves
					or the services managing them. This is done on a per-slice
					basis and proceeds with reporting/notifying the 
					corresponding users.
				</t>
				<t>
					Different deployment models are possible for a Resource
					Orchestration entity:
				</t>
				<t>
					<list style="symbols">
						<t> hierarchical centralized (see <xref target="fig-ro-deploy"/>.A)</t>
						<t> distributed in chain (see <xref target="fig-ro-deploy"/>.B</t>
						<t> distributed full-mesh (see <xref target="fig-ro-deploy"/>.C)</t>
						<t> hierarchical hybrid (see <xref target="fig-ro-hybrid"/>)</t>
					</list>
				</t>
				<t>
					The hierarchical hybrid model is deemed to guarantee the 
					optimal trade-off between effectiveness of control, federation, 
					trust adjacencies and scalability.
				</t>

				<figure title="RO deployment models" align="center" anchor="fig-ro-deploy">
					<preamble/>
					<artwork>
						<![CDATA[ 		

           +-----------+
           |     RO    |
           +-----------+
           /     |    \                 +------+   +------+   +------+
          /      |     \                |  RO  |---|   RO |---|  RO  |
         /       |      \               +------+   +------+   +------+
  +------+   +------+   +------+
  |  RO  |   |  RO  |   |  RO  |
  +------+   +------+   +------+
              (A)                                     (B)


               +--------------------+
               |                    |
           +------+   +------+   +------+   +------+
           |  RO  |---|  RO  |---|  RO  |---|  RO  |
           +------+   +------+   +------+   +------+
               |         |                    |  |
               |         +--------------------+  |
               +---------------------------------+
                              (C)


]]>
					</artwork>
					<postamble/>
				</figure>

				<figure title="Hybrid RO deployment model" align="center" anchor="fig-ro-hybrid">
					<preamble/>
					<artwork>
						<![CDATA[ 		

             +-----------+                      +-----------+
             |     RO    +----------------------+     RO    |
             +-----------+                      +-----------+
             /     |    \                       /     |    \
            /      |     \                     /      |     \
           /       |      \                   /       |      \
    +------+   +------+   +------+     +------+   +------+   +------+
    |  RO  |   |  RO  |   |  RO  |     |  RO  |   |  RO  |   |  RO  |
    +------+   +------+   +------+     +------+   +------+   +------+
]]>
					</artwork>
					<postamble/>
				</figure>


			</section>
		</section>
		<section title="Policy-Based Resource Management">
			<t>	
				Aside from the main functions described above, each Resource 
				Manager is also part of the Authentication and Authorization 
				Infrastructure (AAI).
			</t>
			<t>
				AAI provides the necessary mechanisms to authenticate and 
				authorize users, as well as provide accountability. In order 
				to realize these functions, our architecture suggests 
				the implementation of a ClearingHouse (CH) , which establishes 
				the root of a trust chain. This chain can then be used to 
				verify the identity and privileges of all actors in this 
				architecture. 
			</t>
			<t>
				By using a certificate-based approach, the architecture 
				has flexibility to easily federate different VNF islands.
				By installing ClearingHouse certificates, actors can be 
				verified against different ClearingHouses, and thus can 
				utilize a multitude of resources.
			</t>
			<t>
				A ClearingHouse (CH) comprises a set of related services 
				supporting AAA operations. CH serves as a central location 
				to lookup information about members, slices and other available 
				services in the VNF island. 
			</t>
			<t>
				There are three groups of CH services: 
			</t>
			<t>
				<list style="symbols">
					<t> 
						Registration and management services to lookup 
						for available services in the facility as well 
						as register new members, projects and slice objects. 
					</t>
					<t> 
						Authentication and Authorization services to
						manage the credentials of all entities and 
						enforce predefined policies. 
					</t>
					<t> 
						Accountability services to facilitate tracking 
						of all transactions. 
					</t>
				</list>	
			</t>	
			<t>
				These services are offered by CH with the help of the following 
				functions and authorities.
			</t>	
			<t>
				<list style="symbols">
					<t> 
						The Member Authority (MA) is responsible for managing 
						and asserting user attributes. It generates member certificates 
						for identification purposes and credentials to specify 
						the attributes and roles associated with each member. 
						The MA maintains a database of registered members and 
						their associated information including, but not limited
						to, certificates and credentials, SSH (Secure Shell) 
						and SSL (Secure Sockets Layer) keys as well as the human 
						readable identity information like real name, institute, 
						contact details. 
					</t>
					<t> 
						In addition, a Certificate Revocation List (CRL) can also 
						be accessed from MA for use in certificate verification 
						process.
					</t>
					<t> 
						The Slice Authority (SA) creates and manages slice 
						objects and the associated member credentials (called 
						slice credentials). Slice credentials map member roles 
						and privileges on a slice object, i.e., slice credentials 
						authorize user actions at aggregates within a slice context.
						SA also enables related operations on slice objects like 
						look up, modify, renew, etc. 
					</t>
					<t> 
						The Project Service (PS) hosted at SA maintains a list 
						of existing projects and asserts the member roles. 
					</t>
					<t> 
						The Service Registry (SR) serves as the primary network 
						contact point as it keeps a record of all available 
						registered services such as SA and MA and offers their 
						URIs. 
					</t>
					<t> 
						The Logging Service (LS) realizes accountability by 
						storing the transaction details between user-agents 
						and aggregate managers. 
					</t>
				</list>
			</t>
			<t>
				The user-agents and ROs can communicate with the CH through 
				XMLRPC calls over a secured connection (SSL). 
			</t>
			<t>
				AAI is ultimately responsible for granting access to the 
				resources, and can be further extended through policies, 
				which are a set of rules defined by the administrators to 
				implement an upper-level control on the resource usage 
				(e.g. defining a maximum virtual memory value for a VM 
				resource or a maximum number of flow spaces).
			</t>

			<section title="Certificate-based authN/authZ (C-BAS)">
				<t>	
					Since VNF pools are finite, access to virtual functions 
					and resources should be policed according to set 
					authorization levels throughout the life-cycle of each 
					experiment. 
				</t>
				<t>	
					Access control is also required to ensure that 
					infrastructures remain operational. 
				</t>
				<t>	
					Although a number of solutions for authentication (authN) 
					and authorization(authZ), such as Kerberos and LDAP, 
					already exist, they have several shortcomings: tight-coupling
					of authN/authZ mechanisms with the implementation of the
					architecture; little or no regard for re-usability (i.e., 
					one authN/authZ architecture cannot be reused by a different 
					infrastructure); and no support for a standard access 
					interface between networks and the authN/authZ architecture.
				</t>
				<t>	
					C-BAS, certificate-based authN/authZ solution, is designed to 
					serve all these requirements and include i) multiple authoritative 
					source of trust, ii) flexible system of authorization, and 
					iii) synchronization of authN/authZ entities to realize federations. 
				</t>
				<t>	
					For example, the Registry Service of C-BAS may be exploited
					to implement load balancing and failover features. In addition,
					the evolved architecture of C-BAS makes it robust against 
					disruptions and interference from attackers and enables
					support for various member roles and permissions. 
				</t>
				<t>
					C-BAS employs X.509 certificates and SFA styled credentials
					to realize AAA services. 
				</t>
				<t>
					The implementation of C-BAS is publicly available (www.eict.de/c-bas) 
					and is based on eiSoil (github.com/EICT/eiSoil/wiki) thus exploiting
					its plugin capabilities that enable importing the functionality
					from one plugin module to another.
				</t>
			</section>
			<section title="Resource Managers">
				<section title="VNF Pool manager functionality">
					<t>	
						A VNF pool manager is a functional entity in charge 
						of controlling a specific type of VNFs, being the
						equivalent of the SFA Aggregate Manager (see <xref target="SFA"/>).
						As such, a VNF pool manager is a Resource Manager 
						within the federation, capable of discovering
						resources, capabilities ans functions from physical 
						infrastructure, abstracting them before publishing 
						to the supervising RO and eventually capable of 
						managing specific technology-specific configurations 
						and provisioning towards the actual resource layer.
					</t>
					<t>	
						Whilst the northbound interface of the Resource 
						Manager is abstract and unified across different 
						technology domains (e.g. based on REST or XMLRPC), 
						the southbound interface is based on the specific 
						interfaces exposed by the different types of resources 
						(e.g. OpenFlow, NETCONF, SNMP, CLI, OVSDB, etc.)
					</t>
				</section>
				<section title="OpenFlow-based VNF pool manager">
					<t>	
						The VNF pool manager LAN side could be OpenFlow-based 
						and provide the mechanisms to control the network 
						infrastructure inside a domain with SDN-enabled 
						hardware (typically, OpenFlow-enabled switches and 
						routers). 
						The Inter-island Orchestration Space architecture 
						is agnostic of the physical network resources. 
						For a SDN domain based on OpenFlow users can control
						network behaviour by actively updating the flow 
						tables of the network elements. This update is 
						usually done by a SDN controller, which is 
						configured according the user's requirements. 
						Typically, the controller will respond to an event 
						generated by a network element, such as a flow 
						establishment request, and update the flow tables 
						appropriately.
					</t>
					<t>	
						For the network manager, the VNF pool manager LAN 
						side will provide management functionalities for 
						the overall network resources and virtual network 
						functions in the LAN or data center. This element 
						acts as a proxy between the resources and the 
						SDN controller, and grants or denies the forwarding 
						of control messages.
						The VNF pool manager LAN side provides functions 
						to build a unique flow space for every experimenter 
						so that traffic is isolated and distinguished from 
						that of other slices (e.g. like FlowVisor or OVX do). 
					</t>
					<t>		
						These functionalities can prevent issues arising 
						when several users wish to use the same physical 
						resources. In detail, a flow space can contain a 
						range of differentiators: source or destination IPs 
						or MAC addresses, TCP or UDP ports, for example. 
					</t>
					<t>	
						One way to separate the traffic is assigning a VLAN 
						tag to each packet. In this case, the special purpose
						controller inspects the incoming packet, identifies 
						the VLAN tag and sends it to the corresponding 
						SDN controller.
					</t>
				</section>
				<section title="Stitching Entity VNF pool manager">
					<t>	
						The Stitching Entity VNF pool  Manager is among 
						the pool managers WAN side, and is in charge to 
						control the Stitching Entity (SE), a network 
						element providing necessary translation mechanisms 
						for a slice setup on top of the L2 protocol stack 
						performed in order to hide from a user the real 
						complexity of the multi-domain WAN transport network.
					</t>
					<t>	
						The main responsibility of the SE is to provide 
						at least one of the following network functions:
					</t>
					<t>
						<list style="symbols">
							<t> 
								QinQ, to encapsulate slice traffic into a 
								transport network Ethernet frames, 
							</t>
							<t>
								VLAN translation mechanism to hide from a user 
								the actual VLAN tagging, used by carrier networks 
								while interconnecting two or more VNF islands.
							</t>	
						</list>
					</t>
					<t>
						The SE RM communicates with an RO, a parent 
						control entity, to i) advertise an internal topology 
						and capabilities of the SE under its control, ii) 
						receive requests, and iii) notify the RO about 
						success and failure events.
					</t>
					<t>
						A single SE RM must relate only to a single RO 
						and must be implemented in each VNF island. 
						A single SE RM is responsible for a single SE or 
						a group of SEs, which belong to a network domain 
						and act as an entry point to the island infrastructure.
					</t>
				</section>
				<section title="Transit network VNF pool manager">
					<t>	
						The main responsibility of the Transit VNF pool 
						manager (TN RM) is to support the FELIX architecture 
						with network connectivity mechanisms within particular 
						domains and between them. 
					</t>
					<t>
						In order to deliver the network services, it must 
						be integrated with its southbound interfaces within 
						a particular network domain. 
						Such a domain can use different L1/L2 technologies 
						and may be controlled by a Network Management System 
						(NMS) or by specific interfaces or protocols that 
						are technology-dependent, and unique in each case.
					</t>
					<t>
						The Transit network VNF pool manager must communicate 
						with an RO in order to i) advertise resources under
						its control, ii) receive requests, and iii) notify 
						the RO about success and failure events.
					</t>
					<t>
						A single TN RM must relate only to a single RO.
						A single TN RM is responsible for a group of particular 
						network resources, which belong to a network domain
						and are usually managed by a single entity, i.e. a 
						network administrator or NMS.
					</t>
					<t>
						TN RM usually manages L1/L2 transport networks, which 
						are composed of physical devices using frames/packets
						or circuit switching technologies and support 
						different protocols, e.g. MPLS/GMPLS. In order to support
						inter-island connectivity between existing VNF 
						islands, the TN RM also supports the management
						of VPN set up and tear down procedures.
					</t>
					<t>	
						The TN RM southbound interface can be based on 
						Bandwidth on Demand interfaces, like GMPLS UNI or 
						similar approaches.
					</t>
				</section>

				<section title="RM for virtual computing">
					<t>	
						The function of the Computing Resource pool Manager 
						(C-RM) is to provide a method to assign, set up 
						and configure computing resources. 
					</t>
					<t>	
						C-RM manages physical computing resources, and also 
						the configuration of its own slicing mechanisms 
						(e.g. common hypervisors or other virtualization 
						stacks) and computer resources as presented to the
						user (OS images, network interface configuration, 
						and so on).
					</t>
					<t>		
						The management of physical computing resources 
						should provide a method for rebooting machines, 
						remote control (of a machine's console), or hard 
						power on/off of a machine experiencing problems, 
						for example using a networked PDU (power distribution unit).
					</t>
					<t>	
						Management is typically performed only when problems 
						occur, and when a slice is created, destroyed or 
						modified. Migration of computing resources to other 
						islands may also require reconfiguration. This 
						includes the configuration of network interfaces
						of the computing resource, and setting the
						underlying resources (e.g. hypervisor, physical
						machine), such that those interfaces are bridged
						onto the correct physical interfaces. In particular,
						it may be necessary to configure a slicing mechanism 
						in this bridging, in the case where multiple 
						computing resources have to share a single physical 
						interface. This would typically be achieved using a
						(software-based) SDN solution inside the virtualization 
						platform. Once the SDN solution has been properly 
						set up, it becomes an SDN resource, which is managed 
						by the VNF pool manager LAN side.
					</t>
				</section>
			</section>
		</section>
		<section title="Positioning w.r.t. existing Orchestration  Frameworks">
			<section title="Openstack orchestration">
				<t>
					Among cloud orchestration solution, OpenStack is the facto
					common reference through its Heat module <xref target="os-heat"/>.
				</t>	
				<t>
					Openstack Heat implements an orchestration engine to 
					launch multiple composite cloud applications based on 
					templates in the form of text files that can be 
					treated like code. 
				</t>	
				<t>	
					Many existing CloudFormation templates can be launched on 
					OpenStack. Heat provides both an OpenStack-native ReST API
					and a CloudFormation-compatible	Query API.
				</t>	
				<t>
					A Heat template describes the infrastructure for a 
					cloud application in a text file.
					Infrastructure resources that can be described include: servers, floating ips, volumes, 
					security groups, users, etc.
					Templates can also specify the relationships between resources (e.g. this volume is 
					connected to this server). 
				</t>	
				<t>
					Heat also provides an autoscaling service.
				</t>		
				<t>	
					Heat primarily manages cloud infrastructure, does not 
					support federation and AAI is bundled in the OpenStack 
					framework. 
				</t>
			</section>
			<section title="OpenMANO">
				<t>
					OpenMANO is an open source project which implements 
					the reference architecture for Management &amp; 
					Orchestration under standardization at 
					ETSI's NFV ISG (NFV MANO) <xref target="openmano"/>.
				</t>
				<t>
					OpenMANO consists of two main SW components: 
				</t>
				<t>
					<list style="symbols">
						<t>
							NFV VIM (Virtualised Infrastructure Manager) to provide 
							computing and networking capabilities and to deploy 
							virtual machines.
						</t>
						<t>
							A reference implementation of an NFV-O (Network 
							Functions Virtualisation Orchestrator), which allows
							creation and deletion of VNF templates,	VNF 
							instances, network service templates and network 
							service instances.
						</t>
					</list>
				</t>
				<t>
					OpenMANO does not support federation and AAI as of today.
				</t>
			</section>
			<section title="Other orchestration approaches: federated SDN infrastructures for research experimentation">
				<t>	
					The FELIX project <xref target="FELIX"/> is part of 
					an international research experimentation infrastructure 
					strategy (in Europe under the Future Internet Research 
					Experimentation	- FIRE - framework), with a special 
					focus on SDN and Network Service Interface (NSI) developed 
					by the Open Grid Forum. FELIX is implementing 
					federation and integration of different network and 
					computing resources controlled via SDN and NSI in a 
					multi-domain heterogeneous environment across, initially 
					spanning Europe and Japan. FELIX consortium has designed 
					and is implementing an architecture that extends and 
					advances assets previously developed in other Future 
					Internet projects (e.g. OFELIA), by realizing the 
					federation concepts defined in SFA <xref target="SFA"/>
					with a combination of recursive and hierarchical 
					orchestration, request delegation and inter-domain 
					dependency management. 
					Other research testbeds have been working over the 
					past year on federation of SDN resources. Three of 
					them are particularly relevant on the SDN area:
					OFELIA, FIBRE and GridARS.
				</t>
				<t>
					The OFELIA project <xref target="OFELIA"/> established a 
					pan-European experimental network facility which enables 
					researchers to experiment with real OpenFlow-enabled network 
					equipment and to control and extend the network itself 
					in a precise and dynamic mode.
					The OFELIA facility uses the OpenFlow protocol (and 
					related tools) to support network virtualization and 
					control of the network environment through secure and 
					standardised interfaces. 
					OFELIA consists of two layers. The physical 
					layer is comprised of the computing resources (servers, 
					processors) and network resources (routers, switches, 
					links, wireless devices and optical components). 
					Resources are managed by the OFELIA Control Framework (OCF). 
					Furthermore, the control framework layer contains 
					components which manage and monitor the 
					applications and devices in the physical layer. 
					Aggregate Managers and Resource Managers are components
					of this layer, which can be seen as the combination 
					of three components: Expedient is the GUI and allows 
					the connection and federation
					with different Aggregate Managers via its plugins; 
					Aggregate Managers (AMs) enable
					experimenters to create both compute and network resources
					via the VT AM and OF 
					AM respectively; Resource Managers directly interact 
					with the physical layer,
					provisioning compute resources (OFELIA Xen Agent) or 
					flow rules to establish the
					topology (FlowVisor). 
				</t>
				<t>	
					The FIBRE project <xref target="FIBRE"/> federates SDN 
					testbeds distributed across Europe and Brazil. 
					The FIBRE-EU system builds on top of the OFELIA OCF
					and incorporates several 
					wireless nodes based on commercial Wi-Fi cards and 
					Linux open source drivers. 
					Unlike OFELIA, 
					the FIBRE infrastructure is managed by different types 
					of control and monitoring 
					frameworks (CMFs). 
					FIBRE deployed two top-domain authorities, one in Brazil 
					and one in Europe,
					to manage and own resources in the respective continents. 
					These inter-connected 
					authorities interoperate to allow the federation of
					BR and EU testbeds. 
				</t>
				<t>	
					In Japan, GridARS <xref target="GRIDARS"/>  provides 
					a reference implementation of the Open Grid Forum 
					(OGF) Network Services Interfaces Connection Service 
					(NSI-CS) protocol standard.
					GridARS can coordinate multiple resources (services), 
					such as a
					network connection, virtual machines and storage spaces,
					via the NSICS protocol.
					It provides experimenters a virtual infrastructure,
					which spans several cloud 
					resources, realised by multiple management domains 
					including commercial solutions. 
					GridARS consists of three main components. 
				</t>
			</section>
		</section>
		<section anchor="IANA" title="IANA Considerations">
			<t>	
				No IANA considerations are applicable. 
			</t>
		</section>
		<section anchor="Security" title="Security Considerations">
			<t>
				This document proposes a new architecture for resource and VNF orchestration 
				for the design of which security features are of utmost importance to proceed to 
				operational deployments.  
				Frameworks for Security in SDN are applicable to this document and are discussed in 
				literature, 
				for example, in <xref target="SDNSecurity"/>,  <xref target="SDNSecServ"/> and
				<xref target="SDNSecOF"/>.
				Security considerations regarding specific protocol interfaces are TBD.
			</t>
		</section>
		<section anchor="Acknowledgements" title="Acknowledgements">
			<t>
				This work has been partially supported and funded by the European Commission through 
				the  FP7 ICT FELIX project (Federated Testbeds for Large Scale Infrastructure Experiments,
				grant agreement no. 608638) and the National Institute of Information and 
				Communications Technology (NICT) in Japan.
				The views expressed here are those of the author only.  The European Commission and 
				NICT are not liable for any use that may be made of the information in this document.
			</t>
		</section>
		<section title="Contributors">
			<t>
				Authors would like to acknowledge (in alphabetical order) 
				the following contributors who have provided text, pointers, 
				and ideas for this document:
			</t>
			<t>
				<list style="symbols">
					<t> B. Belter (PSNC, Poland) </t>
					<t> C. Bermudo (i2CAT, Spain) </t>
					<t> T. Kudoh (Univ. Tokyo/AIST, Japan) </t>
					<t> J. Tanaka (KDDI, Japan) </t>
					<t> B. Vermeulen(iMinds, Belgium) </t>
				</list>
			</t>
		</section>
	</middle>

	<back>
		<!-- 		<references title="Normative References">
			&RFC2119;
		</references>
 -->		
		<references title="Informative References">
			<reference anchor="SDNSecOF">
				<front>
					<title abbrev="SDNSecOF">
						OpenFlow: A Security Analysis
					</title>
					<author surname="Kloti, R., Kotronis, V., and P. Smith"/>
					<date year="2013" month="October"/>
				</front>
				<seriesInfo name="21st IEEE International Conference on Network Protocols (ICNP)" value="pp. 1-6"/>
			</reference>
			<reference anchor="SDNSecServ">
				<front>
					<title abbrev="SDNSecServ">
						SDN Security: A Survey
					</title>
					<author surname="Scott-Hayward, S., O'Callaghan, G., and S. Sezer"/>
					<date year="2013" month=""/>
				</front>
				<seriesInfo name="IEEE SDN for Future Networks and Services (SDN4FNS)" value="pp. 1-7"/>
			</reference>
			<reference anchor="SDNSecurity">
				<front>
					<title abbrev="SDNSecurity">
						Towards Secure and Dependable Software-Defined Networks
					</title>
					<author surname="Kreutz, D., Ramos, F., and P. Verissimo"/>
					<date year="2013" month=""/>
				</front>
				<seriesInfo name="Proceedings of the second ACM SIGCOMM workshop on Hot Topics in Software Defined Networking" value="pp. 55-60"/>
			</reference>
			<reference anchor="FELIX">
				<front>
					<title abbrev="FELIX">
						FELIX Project website   
					</title>
					<author surname=""/>
					<date year=""/>
				</front>
				<seriesInfo name="" value="http://www.ict-felix.eu"/>
			</reference>
			<reference anchor="SFA">
				<front>
					<title abbrev="SFA">
						Slice-based Federation Architecture (SFA) v2.0   
					</title>
					<author surname="L. Peterson, R. Ricci, A. Falk and J. Chase"/>
					<date year="2010" month="July"/>
				</front>
				<seriesInfo name="" value=""/>
			</reference>
			<reference anchor="FELIX-D2.1">
				<front>
					<title abbrev="FELIX-D2.1">
						FELIX Deliverable D2.1 - Experiment Use Cases and Requirements   
					</title>
					<author surname="R. Krzywania, W. Bogacki, B. Belter, K. Pentikousis, T. Rothe, G. Carrozzo, N. Ciulli, C. Bermudo, T. Kudoh, A. Takefusa, J. Tanaka and B. Puype"/>
					<date year="2013" month="September"/>
				</front>
				<seriesInfo name="" value="Available online at http://www.ict-felix.eu."/>
			</reference>
			<reference anchor="FELIX-D2.2">
				<front>
					<title abbrev="FELIX-D2.2">
						FELIX Deliverable D2.2 - General Architecture and Functional Blocks   
					</title>
					<author surname="R. Krzywania, W. Bogacki, B. Belter, K. Pentikousis, T. Rothe, M. Broadbent, G. Carrozzo, N. Ciulli, R. Monno, C. Bermudo, A. Vico, C. Fernandez, T. Kudoh, A. Takefusa, J. Tanaka and B. Puype"/>
					<date year="2014" month="February"/>
				</front>
				<seriesInfo name="" value="Available online at http://www.ict-felix.eu."/>
			</reference>
			<reference anchor="middlebox">
				<front>
					<title abbrev="iMiddlebox">
						Flow Processing and the Rise of Commodity Network Hardware   
					</title>
					<author surname="A. Greenhalgh, F. Huici, M. Hoerdt, P. Papadimitriou, M. Handley, and L. Mathy"/>
					<date year="2009" month="April"/>
				</front>
				<seriesInfo name="ACM SIGCOMM Computer Communication Review" value="Volume 39 issue 2"/>
			</reference>
			<reference anchor="cloudstack">
				<front>
					<title abbrev="cloudstack">
						Apache CloudStack documentation. Cloud Infrastructure Concepts    
					</title>
					<author surname=""/>
					<date year="" month=""/>
				</front>
				<seriesInfo name="Available online at" value="http://cloudstack.apache.org/docs/en-US/Apache_CloudStack/4.1.0/html/Admin_Guide/cloud-infrastructure-concepts.html"/>
			</reference>
			<reference anchor="openstack">
				<front>
					<title abbrev="openstack">
						Scaling Openstack    
					</title>
					<author surname=""/>
					<date year="" month=""/>
				</front>
				<seriesInfo name="Available online at" value="http://docs.openstack.org/openstack-ops/content/scaling.html"/>
			</reference>
			<reference anchor="os-heat">
				<front>
					<title abbrev="os-heat">
						OpenStack Orchestration - Heat
					</title>
					<author surname=""/>
					<date year="" month=""/>
				</front>
				<seriesInfo name="Available online at" value="https://wiki.openstack.org/wiki/Heat"/>
			</reference>
			<reference anchor="openmano">
				<front>
					<title abbrev="openmano">
						OpenMANO    
					</title>
					<author surname=""/>
					<date year="" month=""/>
				</front>
				<seriesInfo name="Available online at" value="https://github.com/nfvlabs/openmano/wiki"/>
			</reference>
			<reference anchor="OFELIA">
				<front>
					<title abbrev="OFELIA">
						Design and implementation of the OFELIA FP7 facility: The European OpenFlow testbed    
					</title>
					<author surname="M. Sune, L. Bergesio, H. Woesner, T. Rothe, A. Kopsel, et al."/>
					<date year="2013" month="December"/>
				</front>
				<seriesInfo name="The International Journal of Computer and Telecommunications Networking" value=""/>
			</reference>
			<reference anchor="FIBRE">
				<front>
					<title abbrev="FIBRE">
						FIBRE - An International Testbed for Future Internet Experimentation    
					</title>
					<author surname="T. Salmito, L. Ciuffo, I. Machado, M. Salvador, et al"/>
					<date year="2014" month=""/>
				</front>
				<seriesInfo name="32th Simposio Brasileiro de Redes de Computadores e Sistemas Distribuidos (SBRC&apos;14)" value=""/>
			</reference>
			<reference anchor="GRIDARS">
				<front>
					<title abbrev="GRIDARS">
						GridARS: An Advance Reservation-based Grid Co-allocation Framework for Distributed Computing and Network Resources    
					</title>
					<author surname="[15]	A. Takefusa, H. Nakada, T. Kudoh, Y. Tanaka and S. Sekiguchi"/>
					<date year="2008" month="April "/>
				</front>
				<seriesInfo name="Lecture Notes, Computer Science of the Job Scheduling Strategies for Parallel Processing (JSSPP)" value="vol.4942, pp. 152-168"/>
			</reference>
		</references>
	</back>
</rfc>
